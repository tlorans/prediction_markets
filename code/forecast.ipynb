{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In electricity markets, renewable energy producers (e.g., wind farms) must submit bids ahead of time (e.g., 12-36 hours in advance). However, due to uncertainty in wind power generation, their actual output may deviate from the bid, leading to imbalance costs.\n",
    "\n",
    "Thus, the bid:\n",
    "\n",
    "- Should be close to expected generation to maximize profits.\n",
    "- Must consider imbalance penalties from over- or under-production.\n",
    "- Can be optimized using statistical models (ARMA, GPR, MLE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: polars in /home/tlorans/.local/lib/python3.12/site-packages (1.22.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement fast_excel (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for fast_excel\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3.12 install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fastexcel\n",
      "  Using cached fastexcel-0.12.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting pyarrow>=8.0.0 (from fastexcel)\n",
      "  Using cached pyarrow-19.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Using cached fastexcel-0.12.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached pyarrow-19.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "Installing collected packages: pyarrow, fastexcel\n",
      "Successfully installed fastexcel-0.12.1 pyarrow-19.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3.12 install fastexcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.4 (main, Oct 27 2024, 18:41:26) [GCC 11.4.0]\n",
      "/usr/local/bin/python3.12\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Wind Farms Generation Data: Three wind farms located\n",
    "in Australia including Taralga Wind Farm (TARALGA1) in New\n",
    "SouthWales(NSW1)zone,BaldHillsWindFarm(BALDHWF1)in\n",
    "Victoria (VIC1) zone and Woolnorth Studland Bay / Bluff Point\n",
    "WindFarm (WOOLNTH1) inTasmania (TAS1) zone arechosen for\n",
    "the purpose of our case studies. The installed capacities of these\n",
    "wind farms are 107 MW, 107MW and 140MW, respectively. The\n",
    "proposed method is applied to forecast the hourly generation of\n",
    "these wind farms for a period of nine months spanning from the\n",
    "first day of April to the last day of December of the year 2018.\n",
    "All wind farms generation data with a 5-minute time resolution\n",
    "are obtained from [46].\n",
    "\n",
    "Electricity Market Assumptions: The participants in the\n",
    " day-ahead electricity market are supposed to submit their bids\n",
    " before 12 : 00 a.m. on the current day for each hour of the next\n",
    " operating day, therefore, forecasts are from 12 to 36 hours look\n",
    "ahead times. The electricity prices for the day-ahead market and\n",
    " for the deviations are taken from [47] and [48], respectively. The\n",
    " day-ahead prices, as denoted by rd in equations (12) and (13)\n",
    " of Section II-D, are assumed as the values reported in [47] for\n",
    " each bidding zone including NSW1, VIC1 and TAS1. To estimate\n",
    " the imbalance unit costs in these equations, i.e. λ+ and λ−,as  certain proportion of the day-ahead price, we normalised the\n",
    " four-day average values before the test day reported in [48] and\n",
    " considered them as hourly values of α+ and α− and computed\n",
    " λ+\n",
    " d =(1−α+)rd and λ−\n",
    " d =(1+α−)rd.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8759, 1)\n",
      "(8754, 1)\n",
      "(8757, 1)\n",
      "(8757, 1)\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "#### Wind Farms data one year-Australia\n",
    "\n",
    "filenameA = \"forecast_code/WP_5min_output_2018.xlsx\"\n",
    "\n",
    "# Read data using polars (assuming Excel format is supported)\n",
    "subsetA1 = pl.read_excel(filenameA, sheet_name=\"TARALGA1\")[1:]  # Skip header row\n",
    "subsetA3 = pl.read_excel(filenameA, sheet_name=\"BALDHWF1\")[1:]  # Skip header row \n",
    "subsetA4 = pl.read_excel(filenameA, sheet_name=\"WOOLNTH1\")[1:]  # Skip header row\n",
    "\n",
    "# Function to convert 5-min data to hourly by averaging every 12 rows\n",
    "def aggregate_hourly(df):\n",
    "    arr = df.to_numpy().flatten()  # Convert to NumPy array and flatten\n",
    "    num_rows = len(arr) // 12 * 12  # Ensure it's a multiple of 12\n",
    "    arr = arr[:num_rows]  # Truncate extra rows\n",
    "    hourly_avg = arr.reshape(-1, 12).mean(axis=1)  # Compute hourly averages\n",
    "    return pl.DataFrame({\"hourly_output\": hourly_avg})  # Ensure only 1 column\n",
    "\n",
    "# Apply function to each dataset\n",
    "WP1_hourly = aggregate_hourly(subsetA1)\n",
    "WP3_hourly = aggregate_hourly(subsetA3)\n",
    "WP4_hourly = aggregate_hourly(subsetA4)\n",
    "\n",
    "# Exclude negative values (similar to MATLAB filtering)\n",
    "WP1_hourly = WP1_hourly.with_columns(\n",
    "    pl.when(pl.col(\"hourly_output\") < 0).then(0).otherwise(pl.col(\"hourly_output\")).alias(\"hourly_output\")\n",
    ")\n",
    "WP3_hourly = WP3_hourly.with_columns(\n",
    "    pl.when(pl.col(\"hourly_output\") < 0).then(0).otherwise(pl.col(\"hourly_output\")).alias(\"hourly_output\")\n",
    ")\n",
    "WP4_hourly = WP4_hourly.with_columns(\n",
    "    pl.when(pl.col(\"hourly_output\") < 0).then(0).otherwise(pl.col(\"hourly_output\")).alias(\"hourly_output\")\n",
    ")\n",
    "\n",
    "# Store wind power data in a dictionary similar to MATLAB struct\n",
    "WP = {\n",
    "    \"name\": [\"Tarlaga\", \"Bald Hills\", \"Woolnorth\"],\n",
    "    \"capacity\": [107, 107, 140],\n",
    "    \"location\": [\"NSW\", \"Victoria\", \"Tasmania\"],\n",
    "    \"date\": [\"2018\"],\n",
    "    \"hourly_output\": [WP1_hourly.to_numpy(), WP3_hourly.to_numpy(), WP4_hourly.to_numpy()],\n",
    "}\n",
    "\n",
    "print(WP['hourly_output'][0].shape)\n",
    "\n",
    "# Load Excel file\n",
    "filenameB = \"forecast_code/da_half_hour_price_2018.xlsx\"\n",
    "\n",
    "# Read data using polars\n",
    "subsetB1 = pl.read_excel(filenameB, sheet_name=\"NSW\")[1:]  # Skip header row\n",
    "subsetB2 = pl.read_excel(filenameB, sheet_name=\"VIC\")[1:]  # Skip header row\n",
    "subsetB3 = pl.read_excel(filenameB, sheet_name=\"TAS\")[1:]  # Skip header row\n",
    "\n",
    "\n",
    "# to long format\n",
    "subsetB1 = subsetB1.unpivot(value_name=\"NSW\")[:,1:]\n",
    "subsetB2 = subsetB2.unpivot(value_name=\"VIC\")[:,1:]\n",
    "subsetB3 = subsetB3.unpivot(value_name=\"TAS\")[:,1:]\n",
    "\n",
    "# drop rows with value 0\n",
    "subsetB1 = subsetB1.filter(subsetB1['NSW'] != 0)\n",
    "subsetB2 = subsetB2.filter(subsetB2['VIC'] != 0)\n",
    "subsetB3 = subsetB3.filter(subsetB3['TAS'] != 0)\n",
    "\n",
    "# replace negative value with 0.01\n",
    "subsetB1 = subsetB1.with_columns(\n",
    "    pl.when(pl.col(\"NSW\") < 0).then(0.01).otherwise(pl.col(\"NSW\")).alias(\"NSW\")\n",
    ")\n",
    "subsetB2 = subsetB2.with_columns(\n",
    "    pl.when(pl.col(\"VIC\") < 0).then(0.01).otherwise(pl.col(\"VIC\")).alias(\"VIC\")\n",
    ")\n",
    "subsetB3 = subsetB3.with_columns(\n",
    "    pl.when(pl.col(\"TAS\") < 0).then(0.01).otherwise(pl.col(\"TAS\")).alias(\"TAS\")\n",
    ")\n",
    "\n",
    "\n",
    "# Function to aggregate half-hourly prices to hourly averages\n",
    "def aggregate_half_hourly(df, column_name):\n",
    "    df = df.with_columns(pl.Series(\"index\", range(len(df))))  # Create an index column\n",
    "    df = df.with_columns((pl.col(\"index\") // 2).alias(\"hourly_index\"))  # Group every 2 rows\n",
    "    df = df.group_by(\"hourly_index\", maintain_order = True).agg(pl.col(column_name).mean().alias(column_name))\n",
    "    return df.drop(\"hourly_index\")  # Drop index column after aggregation\n",
    "\n",
    "# Apply function to each dataset\n",
    "da_NSW = aggregate_half_hourly(subsetB1, \"NSW\").to_numpy()\n",
    "da_VIC = aggregate_half_hourly(subsetB2, \"VIC\").to_numpy()\n",
    "da_TAS = aggregate_half_hourly(subsetB3, \"TAS\").to_numpy()\n",
    "\n",
    "# Store market data in a dictionary similar to MATLAB struct\n",
    "DA_price = {\n",
    "    \"Day_ahead_Price\": {\n",
    "        \"NSW\": da_NSW,\n",
    "        \"VIC\": da_VIC,\n",
    "        \"TAS\": da_TAS\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print the final cleaned and aggregated prices\n",
    "print(DA_price[\"Day_ahead_Price\"][\"NSW\"].shape)\n",
    "\n",
    "# Load all 12 sheets from the Excel file\n",
    "filenameC = \"forecast_code/Imb_15min_price_2018.xls\"\n",
    "\n",
    "# Read first sheet and select columns **by index**\n",
    "df = pl.read_excel(filenameC, sheet_id=1)\n",
    "# Select columns by position and cast to float\n",
    "MIP = df[2:, 6:7].rename({\"__UNNAMED__6\": \"MIP\"}).with_columns(pl.col(\"MIP\").cast(pl.Float64))\n",
    "MDP = df[2:, 7:8].rename({\"__UNNAMED__7\": \"MDP\"}).with_columns(pl.col(\"MDP\").cast(pl.Float64))\n",
    "\n",
    "# Append data from the other 11 sheets and ensure float conversion\n",
    "for i in range(2, 13):\n",
    "    df = pl.read_excel(filenameC, sheet_id=i)\n",
    "    \n",
    "    MIP = MIP.vstack(df[2:, 6:7].rename({\"__UNNAMED__6\": \"MIP\"}).with_columns(pl.col(\"MIP\").cast(pl.Float64)))\n",
    "    MDP = MDP.vstack(df[2:, 7:8].rename({\"__UNNAMED__7\": \"MDP\"}).with_columns(pl.col(\"MDP\").cast(pl.Float64)))\n",
    "\n",
    "\n",
    "#**Step 1: Replace negative values in MDP with zero**\n",
    "MDP = MDP.with_columns(pl.when(pl.col(\"MDP\") < 0).then(0).otherwise(pl.col(\"MDP\")))\n",
    "\n",
    "# **Step 2: Convert 15-minute data to hourly by averaging every 4 rows**\n",
    "def aggregate_15min_to_hourly(df, column_name):\n",
    "    df = df.with_columns(pl.Series(\"index\", range(len(df))))  # Create an index column\n",
    "    df = df.with_columns((pl.col(\"index\") // 4).alias(\"hourly_index\"))  # Group every 4 rows\n",
    "    df = df.group_by(\"hourly_index\", maintain_order=True).agg(pl.col(column_name).mean().alias(column_name))\n",
    "    return df.drop(\"hourly_index\")  # Drop index column after aggregation\n",
    "\n",
    "# Apply function to both datasets\n",
    "hourly_MIP = aggregate_15min_to_hourly(MIP, \"MIP\")\n",
    "hourly_MDP = aggregate_15min_to_hourly(MDP, \"MDP\")\n",
    "\n",
    "# **Step 3: Store in a dictionary similar to MATLAB struct**\n",
    "IMB_price = {\n",
    "    \"neg\": hourly_MDP.to_numpy(),\n",
    "    \"pos\": hourly_MIP.to_numpy()\n",
    "}\n",
    "\n",
    "# Print the final cleaned and aggregated prices\n",
    "print(IMB_price[\"neg\"].shape)\n",
    "print(IMB_price[\"pos\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting Wind Power Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2160,) (2160,) (36,) (36,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_daily_imbalance(hourly_MID, hourly_MDP):\n",
    "    \"\"\"\n",
    "    Computes the daily average imbalance prices for each hour of the day.\n",
    "\n",
    "    Args:\n",
    "        hourly_MID (np.array): Historical positive imbalance prices.\n",
    "        hourly_MDP (np.array): Historical negative imbalance prices.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (daily_MID, daily_MDP)\n",
    "    \"\"\"\n",
    "    daily_MID = np.zeros(24)  # Initialize array for daily positive imbalance prices\n",
    "    daily_MDP = np.zeros(24)  # Initialize array for daily negative imbalance prices\n",
    "\n",
    "    for h in range(24):\n",
    "        daily_MID[h] = np.mean(hourly_MID[h:len(hourly_MID)-24+h:24])  # Mimic MATLAB indexing\n",
    "        daily_MDP[h] = np.mean(hourly_MDP[h:len(hourly_MDP)-24+h:24])\n",
    "\n",
    "    return daily_MID, daily_MDP\n",
    "\n",
    "def process_imbalance_prices(which_WP, which_day, DA_price, IMB_price, useful_start, hist_step):\n",
    "    \"\"\"\n",
    "    Processes imbalance prices, calculates adjusted imbalance prices, \n",
    "    and prepares the imbalance price ratios.\n",
    "\n",
    "    Args:\n",
    "        which_WP (int): Wind power plant index.\n",
    "        which_day (int): Forecasting day.\n",
    "        DA_price (dict): Day-ahead market prices.\n",
    "        IMB_price (dict): Imbalance price data.\n",
    "        useful_start (int): Start hour for useful predictions.\n",
    "        hist_step (int): Number of historical hours used for training.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (imbalance_cell, ratio)\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute first_h_day\n",
    "    first_h_day = (which_day * 24) - (useful_start - 1) - hist_step\n",
    "\n",
    "    # Step 1: Historical Imbalance Calculation (last 4 days before `which_day`)\n",
    "    hist_imb = which_day * 24 - 4 * 24  # 4 days lookback\n",
    "\n",
    "    # Day-ahead prices for the forecast day (24 hours)\n",
    "    da_hourly_after = DA_price[\"Day_ahead_Price\"][\"NSW\"][(which_day * 24):((which_day * 24) + 24)]\n",
    "\n",
    "    # Historical Imbalance Prices\n",
    "    hourly_MDP = IMB_price[\"neg\"][hist_imb:(which_day * 24)]\n",
    "    hourly_MID = IMB_price[\"pos\"][hist_imb:(which_day * 24)]\n",
    "\n",
    "    # Compute daily average imbalance prices\n",
    "    daily_MID, daily_MDP = compute_daily_imbalance(hourly_MID, hourly_MDP)\n",
    "\n",
    "    # Step 2: Adjusted Imbalance Prices\n",
    "    lamda_pos_after = daily_MID\n",
    "    lamda_neg_after = daily_MDP\n",
    "\n",
    "    typ = lamda_pos_after / np.max(lamda_pos_after)  # Normalization\n",
    "    tyn = lamda_neg_after / np.max(lamda_neg_after)\n",
    "\n",
    "    lamda_pos_after = (1 - typ) * da_hourly_after\n",
    "    lamda_neg_after = (1 + tyn) * da_hourly_after\n",
    "\n",
    "    lamda_pos = da_hourly_after - lamda_pos_after\n",
    "    lamda_neg = lamda_neg_after - da_hourly_after\n",
    "\n",
    "    # Ratio of Imbalance Prices\n",
    "    ratio = lamda_pos / (lamda_pos + lamda_neg)\n",
    "\n",
    "    # Step 3: Target Forecasting Day Imbalance Prices\n",
    "    lamda_pos_after2 = IMB_price[\"neg\"][(which_day * 24):((which_day * 24) + 24)]\n",
    "    lamda_neg_after2 = IMB_price[\"pos\"][(which_day * 24):((which_day * 24) + 24)]\n",
    "\n",
    "    typ2 = lamda_pos_after2 / np.max(lamda_pos_after2)\n",
    "    tyn2 = lamda_neg_after2 / np.max(lamda_neg_after2)\n",
    "\n",
    "    lamda_pos_after22 = (1 - typ2) * da_hourly_after\n",
    "    lamda_neg_after22 = (1 + tyn2) * da_hourly_after\n",
    "\n",
    "    lamda_pos_after2 = da_hourly_after - lamda_pos_after22\n",
    "    lamda_neg_after2 = lamda_neg_after22 - da_hourly_after\n",
    "\n",
    "    # Step 4: Store in an Imbalance Cell Structure\n",
    "    imbalance_cell = {\n",
    "        \"lamda_pos\": lamda_pos,\n",
    "        \"lamda_neg\": lamda_neg,\n",
    "        \"lamda_pos_after2\": lamda_pos_after2,\n",
    "        \"lamda_neg_after2\": lamda_neg_after2,\n",
    "    }\n",
    "\n",
    "    return imbalance_cell, ratio\n",
    "\n",
    "\n",
    "\n",
    "def train_test_set(which_WP, first_h_day, WP, forecast_step, hist_step):\n",
    "    \"\"\"\n",
    "    Prepares training and test sets for wind power forecasting.\n",
    "\n",
    "    Args:\n",
    "        which_WP (int): Index of wind power plant.\n",
    "        first_h_day (int): Start hour for training.\n",
    "        WP (dict): Wind power dataset.\n",
    "        forecast_step (int): Forecast horizon (hours).\n",
    "        hist_step (int): Number of historical hours used for training.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (x_train, y_train, x_test, y_test)\n",
    "    \"\"\"\n",
    "\n",
    "    # Define training and testing time windows\n",
    "    a1 = first_h_day  # Start of training period\n",
    "    a2 = first_h_day + hist_step  # End of training period (3 months)\n",
    "    b1 = a2  # Start of testing period\n",
    "    b2 = b1 + forecast_step  # End of testing period (forecast horizon)\n",
    "\n",
    "    # Load wind power data\n",
    "    WP_cap = WP[\"capacity\"][which_WP]  # Wind power capacity\n",
    "    WP_hourly = WP[\"hourly_output\"][which_WP]  # Hourly wind power output\n",
    "\n",
    "    # Training set (input: time, output: normalized wind power)\n",
    "    x_train = np.arange(1, (a2 - a1) + 1)  # Time index for training\n",
    "    y_train = (WP_hourly[a1:a2] / WP_cap).flatten()  # Ensure 1D\n",
    "\n",
    "    # Test set (input: time, output: normalized wind power)\n",
    "    x_test = np.arange((a2 - a1) + 1, (a2 - a1) + forecast_step + 1)  # Time index for testing\n",
    "    y_test = (WP_hourly[b1:b2] / WP_cap).flatten()  # Ensure 1D\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "# defined in yearanalysisWP1.m\n",
    "which_WP = 0 # 0 for Taralga, 1 for Bald Hills, 2 for Woolnorth\n",
    "useful_start = 1\n",
    "hist_step = 3*30*24 # historical data used for training (3 months)\n",
    "forecast_step = 36\n",
    "useful_start=13 \n",
    "useful_end=36\n",
    "days = list(range(91, 365))  # Days from 90 to 364\n",
    "which_day = days[0]  # Forecasting day\n",
    "\n",
    "# Defined in Main_Execute.m\n",
    "first_h_day = which_day * 24 - (useful_start - 1) - hist_step\n",
    "WP_cap = WP[\"capacity\"][which_WP]  # Wind power capacity\n",
    "\n",
    "# Compute imbalance prices\n",
    "imbalance_cell, ratio = process_imbalance_prices(which_WP, which_day, DA_price, IMB_price, useful_start, hist_step)\n",
    "\n",
    "# Print results\n",
    "# print(imbalance_cell[\"lamda_pos\"])\n",
    "# print(imbalance_cell[\"lamda_neg\"])\n",
    "# print(imbalance_cell[\"lamda_pos\"].shape)\n",
    "# print(\"Ratio Shape:\", ratio.shape)\n",
    "\n",
    "\n",
    "# Prepare training and test sets\n",
    "x_train, y_train, x_test, y_test = train_test_set(which_WP, first_h_day, WP, forecast_step, hist_step)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tlorans/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/home/tlorans/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 46\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred_arma2, y_sd_arma2, bad_days\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# ARMA Agent Predict WP Output\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m y_pred_arma2, y_sd_arma2, bad_days \u001b[38;5;241m=\u001b[39m \u001b[43mArma2\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhich_day\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred_arma2\u001b[38;5;241m.\u001b[39mshape, y_sd_arma2\u001b[38;5;241m.\u001b[39mshape, bad_days)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred_arma2)\n",
      "Cell \u001b[0;32mIn[27], line 24\u001b[0m, in \u001b[0;36mArma2\u001b[0;34m(y_train, which_day, forecast_step)\u001b[0m\n\u001b[1;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m ARIMA(y_train, order\u001b[38;5;241m=\u001b[39m(num_y, \u001b[38;5;241m0\u001b[39m, num_e))  \u001b[38;5;66;03m# No differencing (d=0)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m fitted_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Forecast the next `forecast_step` steps\u001b[39;00m\n\u001b[1;32m     27\u001b[0m forecast_results \u001b[38;5;241m=\u001b[39m fitted_model\u001b[38;5;241m.\u001b[39mget_forecast(steps\u001b[38;5;241m=\u001b[39mforecast_step)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/statsmodels/tsa/arima/model.py:395\u001b[0m, in \u001b[0;36mARIMA.fit\u001b[0;34m(self, start_params, transformed, includes_fixed, method, method_kwargs, gls, gls_kwargs, cov_type, cov_kwds, return_params, low_memory)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m     method_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 395\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcov_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_kwds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_kwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_params:\n\u001b[1;32m    399\u001b[0m         res\u001b[38;5;241m.\u001b[39mfit_details \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mmlefit\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/mlemodel.py:705\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[0;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m         flags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhessian_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m optim_hessian\n\u001b[1;32m    704\u001b[0m     fargs \u001b[38;5;241m=\u001b[39m (flags,)\n\u001b[0;32m--> 705\u001b[0m     mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mskip_hessian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# Just return the fitted parameters if requested\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_params:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/statsmodels/base/model.py:566\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_t\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    565\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Optimizer()\n\u001b[0;32m--> 566\u001b[0m xopt, retvals, optim_settings \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mhessian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;66;03m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[1;32m    576\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/statsmodels/base/optimizer.py:243\u001b[0m, in \u001b[0;36mOptimizer._fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    240\u001b[0m     fit_funcs\u001b[38;5;241m.\u001b[39mupdate(extra_fit_funcs)\n\u001b[1;32m    242\u001b[0m func \u001b[38;5;241m=\u001b[39m fit_funcs[method]\n\u001b[0;32m--> 243\u001b[0m xopt, retvals \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m optim_settings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: method, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_params\u001b[39m\u001b[38;5;124m'\u001b[39m: start_params,\n\u001b[1;32m    249\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: maxiter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_output\u001b[39m\u001b[38;5;124m'\u001b[39m: full_output,\n\u001b[1;32m    250\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfargs\u001b[39m\u001b[38;5;124m'\u001b[39m: fargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[1;32m    251\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretall\u001b[39m\u001b[38;5;124m'\u001b[39m: retall, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_fit_funcs\u001b[39m\u001b[38;5;124m\"\u001b[39m: extra_fit_funcs}\n\u001b[1;32m    252\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/statsmodels/base/optimizer.py:660\u001b[0m, in \u001b[0;36m_fit_lbfgs\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m approx_grad:\n\u001b[1;32m    658\u001b[0m     func \u001b[38;5;241m=\u001b[39m f\n\u001b[0;32m--> 660\u001b[0m retvals \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin_l_bfgs_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[1;32m    666\u001b[0m     xopt, fopt, d \u001b[38;5;241m=\u001b[39m retvals\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py:237\u001b[0m, in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    225\u001b[0m callback \u001b[38;5;241m=\u001b[39m _wrap_callback(callback)\n\u001b[1;32m    226\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miprint\u001b[39m\u001b[38;5;124m'\u001b[39m: iprint,\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxcor\u001b[39m\u001b[38;5;124m'\u001b[39m: m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxls\u001b[39m\u001b[38;5;124m'\u001b[39m: maxls}\n\u001b[0;32m--> 237\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m d \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjac\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    240\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    241\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfuncalls\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfev\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    242\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    243\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarnflag\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m    244\u001b[0m f \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:344\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:306\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_orig_grad \u001b[38;5;129;01min\u001b[39;00m FD_METHODS:\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:47\u001b[0m, in \u001b[0;36m_wrapper_grad.<locals>.wrapped1\u001b[0;34m(x, f0)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped1\u001b[39m(x, f0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     46\u001b[0m     ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfinite_diff_options\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/optimize/_numdiff.py:519\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/optimize/_numdiff.py:592\u001b[0m, in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    590\u001b[0m     x1[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m h[i]\n\u001b[1;32m    591\u001b[0m     dx \u001b[38;5;241m=\u001b[39m x1[i] \u001b[38;5;241m-\u001b[39m x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[0;32m--> 592\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m f0\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3-point\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[1;32m    594\u001b[0m     x1[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m h[i]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/optimize/_numdiff.py:470\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39misdtype(x\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal floating\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    468\u001b[0m     x \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(x, x0\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 470\u001b[0m f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fun` return value has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    473\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmore than 1 dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:20\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     16\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/statsmodels/base/model.py:534\u001b[0m, in \u001b[0;36mLikelihoodModel.fit.<locals>.f\u001b[0;34m(params, *args)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(params, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloglike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m nobs\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/mlemodel.py:940\u001b[0m, in \u001b[0;36mMLEModel.loglike\u001b[0;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m complex_step:\n\u001b[1;32m    938\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minversion_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m INVERT_UNIVARIATE \u001b[38;5;241m|\u001b[39m SOLVE_LU\n\u001b[0;32m--> 940\u001b[0m loglike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloglike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomplex_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplex_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;66;03m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;66;03m# likelihood to avoid scale issues, but the averaging is done\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;66;03m# automatically in the base model `fit` method\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loglike\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/kalman_filter.py:1001\u001b[0m, in \u001b[0;36mKalmanFilter.loglike\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;124;03mCalculate the loglikelihood associated with the statespace model.\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;03m    The joint loglikelihood.\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    999\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1000\u001b[0m                   MEMORY_CONSERVE \u001b[38;5;241m^\u001b[39m MEMORY_NO_LIKELIHOOD)\n\u001b[0;32m-> 1001\u001b[0m kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1002\u001b[0m loglikelihood_burn \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloglikelihood_burn\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1003\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloglikelihood_burn)\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m&\u001b[39m MEMORY_NO_LIKELIHOOD):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/kalman_filter.py:924\u001b[0m, in \u001b[0;36mKalmanFilter._filter\u001b[0;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_state(prefix\u001b[38;5;241m=\u001b[39mprefix, complex_step\u001b[38;5;241m=\u001b[39mcomplex_step)\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Run the filter\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m \u001b[43mkfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kfilter\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "def Arma2(y_train, which_day, forecast_step):\n",
    "    \"\"\"\n",
    "    Implements an ARMA model to predict wind power outputs.\n",
    "\n",
    "    Args:\n",
    "        y_train (np.array): Training data (normalized wind power).\n",
    "        which_day (int): Forecasting day.\n",
    "        forecast_step (int): Number of steps to forecast.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (y_pred_arma2, y_sd_arma2, bad_days)\n",
    "    \"\"\"\n",
    "    num_y = 72  # AR lags\n",
    "    num_e = 36  # MA lags\n",
    "\n",
    "    try:\n",
    "        # Define ARMA model (ARMA(p=72, q=36))\n",
    "        model = ARIMA(y_train, order=(num_y, 0, num_e))  # No differencing (d=0)\n",
    "        \n",
    "        # Fit the model\n",
    "        fitted_model = model.fit()\n",
    "        \n",
    "        # Forecast the next `forecast_step` steps\n",
    "        forecast_results = fitted_model.get_forecast(steps=forecast_step)\n",
    "        \n",
    "        y_pred_arma2 = forecast_results.predicted_mean\n",
    "        y_sd_arma2 = forecast_results.se_mean  # Standard error\n",
    "        \n",
    "        bad_days = []\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ARMA Model failed for day {which_day}: {e}\")\n",
    "        \n",
    "        # If the model fails, return random predictions\n",
    "        y_pred_arma2 = np.random.rand(forecast_step)\n",
    "        y_sd_arma2 = np.random.rand(forecast_step)\n",
    "        bad_days = [which_day]\n",
    "\n",
    "    return y_pred_arma2, y_sd_arma2, bad_days\n",
    "\n",
    "\n",
    "# ARMA Agent Predict WP Output\n",
    "y_pred_arma2, y_sd_arma2, bad_days = Arma2(y_train, which_day, forecast_step)\n",
    "print(y_pred_arma2.shape, y_sd_arma2.shape, bad_days)\n",
    "print(y_pred_arma2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Forecast Distributions to Probability Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Market\n",
    "\n",
    "\n",
    "\n",
    "Clearance mechanisms in prdiction markets:\n",
    "- Continuous Double Auction (CDA)\n",
    "- Automated Market Maker (AMM)\n",
    "\n",
    "with CD mechanism, buyers and selelrs of the contracts offer bid and ask prices and trade happens when the offered prices match. Main problem is the lack of liquidity because the bid-ask spreads often remain wide. Possible solution is the use of AMM to be always available to take the other side of an order of buying or selling, therefore providing liquidity to the market\n",
    "\n",
    "Logarithmic Market Scoring Rule (LMSR): arbitratege free amm with continous price function and payoff values known at the time of the trade where the price of shares reflects the probability of the outcome.\n",
    "\n",
    "The cost and price of contracts (shares) in LMSR are given by:\n",
    "\n",
    "\\begin{equation}\n",
    "\\pi_r (b, \\pi_c, q) = \\frac{1}{(1 + \\frac{1/\\pi_c - 1}{\\exp(q / b)})}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "C(b, \\pi_c, q) = b \\ln (\\pi_c (exp(q/b) - 1) +1)\n",
    "\\end{equation}\n",
    "\n",
    "where $b$ is the AMM parameter which controls the available liquidity in the market, $q$ is the quantity of shares to be trader $\\pi_c$ is the current market price and finally $\\pi_r(b, \\pi_c, q)$ and $C(b, \\pi_c, q)$ are the resulting price and the cost function respectively. \n",
    "\n",
    "The first initial price of shares is set by the AMM as $\\pi_c = \\pi_0$. In previous equations, positive values of $q$ indicate buying shares while negative values of $q$ correspond to selling shares. Therefore, buying shares increases the market price while selling shares decreses the price.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
